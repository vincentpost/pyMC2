{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pandas to process logger data\n",
    "\n",
    "This notebook demonstrates how to use Pandas to read and process data from pressure transducers. The tasks to be completed are\n",
    "1. Load the data\n",
    "2. Fill any gaps\n",
    "3. Shift the measured pressures because the logger was placed in a different position after downloading\n",
    "4. Subtract the atmospheric pressure to obtain the water column height above the logger\n",
    "5. Determine the seasonal trend in water level\n",
    "\n",
    "First the required libraries must be imported of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file to be loaded is the native CSV file format for this logger type. While this can be done using `read_csv`, it can be quite a puzzle to provide all the right keywords (and there is no general recipe, each logger manufacturer have their own format). The first 63 lines are metadata, so we provide `skiprows=63`, the last line is a text string that we do not wish to import, hence the `skipfooter=1`. We'd like to set the DataFrame index to a datetime format using the values in the first column, which is accomplished by `index_col=0` and `parse_dates=True`. Columns are not separated by a comma but by a semicolon, which is why we need `sep=';'`. Also note that we must provide the character encoding, which is typical for files of this type and which encoding format to choose is usually a matter of trial and error (StackOverflow is your friend in this case). Note that if you wanted to get rid of the warning you could also include `engine='python'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = Path(\"data\", \"Rabingha\", \"Rabingha_Forage_230705130949_X1044.CSV\")\n",
    "df_wl = pd.read_csv(\n",
    "    fpath,\n",
    "    skiprows=63,\n",
    "    skipfooter=1,\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    "    sep=';',\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    # engine='python',\n",
    ")\n",
    "df_wl.head();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plot gives a first impression of the data that were loaded. It is obvious when the data were downloaded and from the shift in the data points we can see that the logger was not placed back at the right depth in the well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_wl[\"Pressure[mH2O]\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out when the logger was not inside the well, we check when the pressure was less than 15 m of water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx0 = df_wl[\"Pressure[mH2O]\"] < 15\n",
    "df_wl.loc[idx0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An approach to get rid of the outliers on these two dates is to set the corresponding values to NaN (not a number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wl.loc[idx0, :] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing anything else, let's first fix the problem that the logger was shifted. To get a better picture we can plot the data two weeks before and after downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tout = df_wl.loc[idx0].index[0]\n",
    "idx1 = df_wl.index < tout\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_wl.loc[idx1, \"Pressure[mH2O]\"])\n",
    "ax.plot(df_wl.loc[~idx1, \"Pressure[mH2O]\"], color='lightgray')\n",
    "\n",
    "dt = pd.Timedelta('14D')\n",
    "ax.set_xlim(tout - dt, tout + dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shift is about one meter. It is remedied by adding this value to the pressure data after the logger was placed back in the well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot again\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_wl.loc[idx1, \"Pressure[mH2O]\"])\n",
    "ax.plot(df_wl.loc[~idx1, \"Pressure[mH2O]\"], color='lightgray')\n",
    "\n",
    "# Add the offset and display\n",
    "dwl = 1.0\n",
    "df_wl.loc[~idx1, \"Pressure[mH2O]\"] = df_wl.loc[~idx1, \"Pressure[mH2O]\"] + dwl\n",
    "ax.plot(df_wl.loc[~idx1, \"Pressure[mH2O]\"])\n",
    "\n",
    "ax.set_xlim(tout - dt, tout + dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still the two missing data values that need to be dealt with. The values on 23 september 2021 can be estimated using linear interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use interpolation to fill the gap at the first erroneous reading\n",
    "print(df_wl.loc[idx0])\n",
    "df_wl = df_wl.interpolate()\n",
    "print(df_wl.loc[idx0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it is the last reading, the value on 5 July 2023 can be deleted like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wl = df_wl.iloc[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the water pressures have been corrected, let's import the atmospheric pressure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = Path(\"data\", \"Rabingha\", \"Rabingha_Baro_230705125953_BX059.CSV\")\n",
    "df_p = pd.read_csv(\n",
    "    fpath,\n",
    "    skiprows=51,\n",
    "    skipfooter=1,\n",
    "    sep=';',\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    engine='python',\n",
    ")\n",
    "df_p.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw a graph to get a first impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_p[\"Pressure[mH2O]\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding the atmospheric pressures to `df_wl`, it becomes easy to subtract the atmospheric pressure from the total pressure (water + atmospheric) to get the water column height above the logger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_wl[\"patm\"] = df_p[\"Pressure[mH2O]\"]\n",
    "df_wl[\"wl_corr\"] = df_wl[\"Pressure[mH2O]\"] - df_wl[\"patm\"]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_wl[\"wl_corr\"])\n",
    "# ax.set_xlim(tout - dt, tout + dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To separate the seasonal fluctuation from the daily pumping we can get the daily maximum and minimum water levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wl_d_min = df_wl[\"wl_corr\"].resample('1D').min()\n",
    "df_wl_d_max = df_wl[\"wl_corr\"].resample('1D').max()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_wl_d_min)\n",
    "ax.plot(df_wl_d_max);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between the maximum and the minimum is the daily range in water level. Plotting it may give a first idea about whether or not there is less pumping during the wet season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2)\n",
    "\n",
    "# Plot the maximum to get an idea of the seasonal trend\n",
    "ax0.plot(df_wl_d_max)\n",
    "ax0.set_ylabel(\"Daily max. water level (m)\")\n",
    "\n",
    "# Determine the daily range and plot\n",
    "df_wl_diff = df_wl_d_max - df_wl_d_min\n",
    "ax1.plot(df_wl_diff)\n",
    "ax1.set_ylabel(\"Daily water level range (m)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more sophisticated times series analysis options, see the <A href=\"https://pastas.readthedocs.io/en/master/\">Pastas</A> package."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geopandas_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
